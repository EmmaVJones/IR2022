## global
board_register_rsconnect(key = conn$CONNECT_API_KEY,  #Sys.getenv("CONNECT_API_KEY"),
                         server = conn$CONNECT_SERVER)#Sys.getenv("CONNECT_SERVER"))




# ui 

tabPanel('Data Upload',
         h3('Tool Overview'),
         p("The Riverine Assessment Tool is designed to expedite analysis, assessment
                                            decisions, and quality assurance/quality control (QA/QC) procedures for Virginia's
                                            2022 Integrated Report (IR). The data window analyzed covers 
                                            January 1, 2015 to December 31, 2020. Users can expect significant time savings
                                            on repetitive procedures including: raw data organization from disparate databases, 
                                            geospatial organization of stations by assessment unit, standard/criteria calculations, 
                                            and data visualization."),
         p('This application represents the second iteration of an automated assessment tool. The datasets
                                            and parameters chosen for analysis readily lend themselves to automated processing. Future versions
                                            of the tool may include additional datasets and analyses.'),
         p('For feedback, troubleshooting, and questions regarding analyses or missing data, please contact 
                                            Emma Jones (emma.jones@deq.virginia.gov)'),
         br(),
         h3('Tool Inputs'),br(),
         h4('Prepopulated Tool Inputs'),
         p("Some data sources are compiled for users and programmed into the app, requiring no user manipulation.
                                            These datasets include: "),
         tags$ul(
           tags$li('Conventionals- CEDS data pulled and analyzed by Roger Stewart (roger.stewart@deq.virginia.gov) for each 
                                            Integrated Report data window.'), 
           tags$li('Water Column and Sediment Metals- CEDS data pulled, filtered, and analyzed by Roger Stewart for each 
                                            Integrated Report data window.'), 
           tags$li("Statewide Assessment (spatial) layer- The spatial dataset that identifies each regional office's watersheds."),
           tags$li("CEDS EDAS- Statewide macroinvertebrate data and stream condition indices are pulled and organized from the 
                                            Integrated Report data window. Contact Jason Hill (jason.hill@deq.virginia.gov) or your regional
                                                    biologist with dataset questions.")  ),
         br(),
         h4('User Defined Tool Inputs'),
         p('In order to allow for more flexible assessment unit updates as required throughout the assessment process,
                                             users must upload certain datasets that follow a specified template. These include their regional
                                             Stations Table (generated by the automated assessment scripts) and Regional Assessment Unit shapefiles.'),
         h5('Stations Table- Generated by the Automated Assessment Tool'),
         helpText('This dataset is derived before any Riverine Assessment Tool analysis 
                                                   procedures can commence using information provided by assessors from the ',
                  span(strong('Regional Assessment Metadata Validation Tool.')), 
                  'After completing the necessary WQS and AU attribution steps overviewed in the ',
                  span(strong('Regional Assessment Metadata Validation Tool')),'once, users are provided
                                                   an initial automated assessment (Stations Table) to upload to this application and/or
                                                   the ',span(strong('CEDS WQA Stations Table Bulk Upload')), ' tool. Should any assessment 
                                                   units change throughout the assessment process, users have the ability to update their local
                                                   Stations Table and Regional Assessment Units spatial layers with the required changes and 
                                                   upload those new datasets to this application. With that updated information, this tool will
                                                   reflect the changes to the user. This process may be repeated as many times as is necessary 
                                                   throughout the assessment process. After stations and AUs are reviewed, users may upload
                                                   their Stations Table to the ', span(strong('CEDS WQA Stations Table Bulk Upload')), ' tool.'),
         helpText(strong('A note on Inversioning spatial data: '),"If assessment unit changes are necessary throughout
                                                   the course of the assessment process, the user should update their local AU spatial dataset, sync 
                                                   these changes to the statewide spatial datasest, and export a local copy of this updated spatial
                                                   dataset for use in the assessment applications. Users should also alter the assessment unit name
                                                   attributed to the station(s) in the Station Table to ensure the assessment applications can appropriately
                                                   reorganize data according to the user's changes."),
         fileInput('stationsTable','Upload your Regional Stations Table.',
                   accept = c(".csv")),
         h5('Regional Assessment Units'),
         helpText(span('This shapefile is the current working copy of the regional assessment units.',
                       strong('It will be uploaded to the app on startup for you to expedite application rendering
                                                        time.'), ' Any changes to the regional dataset (e.g. split an assessment 
                                                        unit) should be synced with the statewide version and a copy of the ', strong('new spatial 
                                                        dataset should be sent to Emma Jones (emma.jones@deq.virginia.gov) to update on the server.')))
         #h6(strong('To view or change the location of the Regional Assessment Units shapefile sourced
         #          by the application, see the AUshapefileLocation.R script.'))
         #fileInput('regionalAUshapefile','Choose your Regional Assessment Unit shapefile.',
         #          accept = c(".shp",#)),# only need .shp for st_read 
         #                     ".dbf",".prj",".sbn",".sbx","shp.xml",".shx"), multiple = T),
),







# pre server

# Pull data from server
conventionals <- pin_get("conventionals2022IRdraft", board = "rsconnect") %>%
  filter(FDT_DATE_TIME >= "2015-01-01 00:00:00 UTC" )
vahu6 <- st_as_sf(pin_get("vahu6", board = "rsconnect")) # bring in as sf object
WQSlookup <- pin_get("WQSlookup-withStandards",  board = "rsconnect")
# placeholder for now, shouldn't be a spatial file
historicalStationsTable <- st_read('data/GIS/2020_wqms.shp') %>%
  st_drop_geometry()#read_csv('data/stationsTable2022begin.csv') # last cycle stations table (forced into new station table format)
WCmetals <- pin_get("WCmetals-2020IRfinal",  board = "rsconnect")
Smetals <- pin_get("Smetals-2020IRfinal",  board = "rsconnect")
WQMstationFull <- pin_get("WQM-Station-Full", board = "rsconnect")
VSCIresults <- pin_get("VSCIresults", board = "rsconnect") %>%
  filter( between(`Collection Date`, assessmentPeriod[1], assessmentPeriod[2]) ) %>% # get ecoregion info
  left_join(dplyr::select(WQMstationFull, WQM_STA_ID, EPA_ECO_US_L3CODE, EPA_ECO_US_L3NAME) %>%
              distinct(WQM_STA_ID, .keep_all = TRUE), by = c('StationID' = 'WQM_STA_ID'))
VCPMI63results <- pin_get("VCPMI63results", board = "rsconnect") %>%
  filter( between(`Collection Date`, assessmentPeriod[1], assessmentPeriod[2]) ) %>% # get ecoregion info
  left_join(dplyr::select(WQMstationFull, WQM_STA_ID, EPA_ECO_US_L3CODE, EPA_ECO_US_L3NAME) %>%
              distinct(WQM_STA_ID, .keep_all = TRUE), by = c('StationID' = 'WQM_STA_ID'))
VCPMI65results <- pin_get("VCPMI65results", board = "rsconnect") %>%
  filter( between(`Collection Date`, assessmentPeriod[1], assessmentPeriod[2]) ) %>% # get ecoregion info
  left_join(dplyr::select(WQMstationFull, WQM_STA_ID, EPA_ECO_US_L3CODE, EPA_ECO_US_L3NAME) %>%
              distinct(WQM_STA_ID, .keep_all = TRUE), by = c('StationID' = 'WQM_STA_ID'))





# server

# real
stationTable <- reactive({
 req(input$stationsTable)
  inFile <- input$stationsTable
  stationTable <- read_csv(inFile$datapath,
                           col_types = cols(COMMENTS = col_character())) %>% # force to character bc parsing can incorrectly guess logical based on top 1000 rows
    #fix periods in column names from excel
    as_tibble()
  # Remove stations that don't apply to application
  lakeStations <- filter_at(stationTable, vars(starts_with('TYPE')), any_vars(. == 'L'))
  stationTable <- filter(stationTable, !STATION_ID %in% lakeStations$STATION_ID) %>%
    # add WQS information to stations
    left_join(WQSlookup, by = c('STATION_ID'='StationID')) %>%
    mutate(CLASS_BASIN = paste(CLASS,substr(BASIN, 1,1), sep="_")) %>%
    mutate(CLASS_BASIN = ifelse(CLASS_BASIN == 'II_7', "II_7", as.character(CLASS))) %>%
    # Fix for Class II Tidal Waters in Chesapeake (bc complicated DO/temp/etc standard)
    left_join(WQSvalues, by = 'CLASS_BASIN') %>%
    dplyr::select(-c(CLASS.y,CLASS_BASIN)) %>%
    rename('CLASS' = 'CLASS.x') 
  # last cycle had code to fix Class II Tidal Waters in Chesapeake (bc complicated DO/temp/etc standard) but not sure if necessary
  
  return(stationTable)
})
# for testing
stationTable <- reactive({
  stationTable <-  read_csv('userDataToUpload/processedStationData/stationTableResults.csv',
                            col_types = cols(COMMENTS = col_character()))  # force to character bc parsing can incorrectly guess logical based on top 1000 rows
  # Remove stations that don't apply to application
  lakeStations <- filter_at(stationTable, vars(starts_with('TYPE')), any_vars(. == 'L'))
  stationTable <- filter(stationTable, !STATION_ID %in% lakeStations$STATION_ID) %>%
    # add WQS information to stations
    left_join(WQSlookup, by = c('STATION_ID'='StationID')) %>%
    mutate(CLASS_BASIN = paste(CLASS,substr(BASIN, 1,1), sep="_")) %>%
    mutate(CLASS_BASIN = ifelse(CLASS_BASIN == 'II_7', "II_7", as.character(CLASS))) %>%
    # Fix for Class II Tidal Waters in Chesapeake (bc complicated DO/temp/etc standard)
    left_join(WQSvalues, by = 'CLASS_BASIN') %>%
    dplyr::select(-c(CLASS.y,CLASS_BASIN)) %>%
    rename('CLASS' = 'CLASS.x') 
  # last cycle had code to fix Class II Tidal Waters in Chesapeake (bc complicated DO/temp/etc standard) but not sure if necessary
  
  return(stationTable)
}) #for testing




# real
# Pull AU data from server
regionalAUs <- reactive({ 
  req(input$pullAUs)
  withProgress(message = 'Reading in Large Spatial File',
               st_zm(st_as_sf(pin_get(paste0(input$DEQregionSelection, 'workingAUriverine'), board = 'rsconnect')) )) })
# for testing
# Pull AU data from server
regionalAUs <- reactive({ 
  req(input$pullAUs)
  withProgress(message = 'Reading in Large Spatial File',
               regionalAUsForTesting ) }) # for testing
